<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="" />
  <meta name="author" content="and contributors" />
   <title>Propagação de incertezas</title>  
  <link rel="shortcut icon" type="image/png" href="/modelagem_matematica/assets/images/favicon.png"/>
  <link rel="stylesheet" href="/modelagem_matematica/css/base.css"/>
  
  <script src="/modelagem_matematica/libs/mousetrap/mousetrap.min.js"></script>

  
    <link rel="stylesheet" href="/modelagem_matematica/libs/highlight/github.min.css">
    <script src="/modelagem_matematica/libs/highlight/highlight.pack.js"></script>
    <script src="/modelagem_matematica/libs/highlight/julia.min.js"></script>
    <script>
      document.addEventListener('DOMContentLoaded', (event) => {
        document.querySelectorAll('pre').forEach((el) => {
          hljs.highlightElement(el);
        });
      });
    </script>
  

  
    <link rel="stylesheet" href="/modelagem_matematica/libs/katex/katex.min.css">
  
</head>

<body>

  <div class="books-container">

  <aside class="books-menu">
  <input type="checkbox" id="menu">
  <label for="menu">☰</label>

  <div class="books-title">
    <a href="/modelagem_matematica/">Modelagem Matemática</a>
  </div>

  <br />

  <div class="books-subtitle">
    Notas de aula
  </div>

  <br />

  <div class="books-author">
    <a href="https://rmsrosa.github.io">Ricardo M. S. Rosa</a>
  </div>

  <div class="books-menu-content">
    <div class="menu-level-1">
    <li><a href="/modelagem_matematica/pages/intro">Introdução</a></li>
    </div>
    <div class="menu-level-1">
    <li>PARTE I</li>
    </div>
    <div class="menu-level-1">
    <li>1. Preliminares</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/modelagem_matematica/pages/jupytered/c01/0101-Aspectos_curso">1.1. Aspectos do curso</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/modelagem_matematica/pages/jupytered/c01/0102-Instalando_acessando_Julia">1.2. Instalando e acessando o Julia</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/modelagem_matematica/pages/jupytered/c01/0103-Primeiros_passos_Julia">1.3. Primeiros passos em Julia</a></li>
    </div>
    <div class="menu-level-1">
    <li>PARTE II</li>
    </div>
    <div class="menu-level-1">
    <li>2. Princípios de Modelagem Matemática</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/modelagem_matematica/pages/jupytered/c02/0201-Principios_basicos">2.1. Princípios básicos de modelagem</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/modelagem_matematica/pages/jupytered/c02/0202-Exemplos_tipos_modelagem">2.2. Exemplos de tipos de modelagem</a></li>
    </div>
    <div class="menu-level-1">
    <li>3. Análise Dimensional</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/modelagem_matematica/pages/jupytered/c03/0301-Quantidades_unidades_dimensoes">3.1. Quantidades, unidades e dimensões</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/modelagem_matematica/pages/jupytered/c03/0302-BuckinghamPi">3.2. Análise dimensional e o Teorema de Buckingham-Pi</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/modelagem_matematica/pages/jupytered/c03/0303-Unidades_Julia">3.3. Trabalhando com unidades e dimensões em Julia</a></li>
    </div>
    <div class="menu-level-1">
    <li>4. Ajuste de Parâmetros</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/modelagem_matematica/pages/jupytered/c04/0401-Minimos_quadrados_ajuste">4.1. Mínimos quadrados e o ajuste de parâmetros</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/modelagem_matematica/pages/jupytered/c04/0402-Exemplos_ajuste_linear">4.2. Exemplos de ajuste linear</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/modelagem_matematica/pages/jupytered/c04/0403-Modelos_redutiveis_linear_aplicacoes">4.3. Modelos redutíveis ao caso linear nos parâmetros e aplicações</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/modelagem_matematica/pages/jupytered/c04/0404-Minimos_quadrados_nao_linear">4.4. Mínimos quadrados não-linear</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/modelagem_matematica/pages/jupytered/c04/0405-Exemplos_ajuste_naolinear">4.5. Exemplos de ajuste não-linear de parâmetros</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/modelagem_matematica/pages/jupytered/c04/0406-Redes_neurais">4.6. Redes neurais</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/modelagem_matematica/pages/jupytered/c04/0407-Ajuste_em_redes_neurais">4.7. Ajuste de parâmetros em modelos de redes neurais</a></li>
    </div>
    <div class="menu-level-1">
    <li>5. Erros e Incertezas</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/modelagem_matematica/pages/jupytered/c05/0501-Erros_e_incertezas">5.1. Erros e incertezas</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/modelagem_matematica/pages/jupytered/c05/0502-Minimos_quadrados_verossimilhanca">5.2. Mínimos quadrados, maximização da verossimilhança e quantificação de incertezas em regressões lineares</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/modelagem_matematica/pages/jupytered/c05/0503-Propagacao_incertezas">5.3. Propagação de incertezas</a></li>
    </div>
    <div class="menu-level-1">
    <li>6. Avaliação de Modelos</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/modelagem_matematica/pages/jupytered/c06/0601-Qualidade_do_modelo">6.1. Qualidade do ajuste</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/modelagem_matematica/pages/jupytered/c06/0602-Validacao_do_modelo">6.2. Validação de modelos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/modelagem_matematica/pages/jupytered/c06/0603-Comparacao_de_modelos">6.3. Comparação de modelos</a></li>
    </div>
    <div class="menu-level-1">
    <li>PARTE III</li>
    </div>
    <div class="menu-level-1">
    <li>7. Mecânica</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/modelagem_matematica/pages/jupytered/c07/0701-Mecanica_Newtoniana">7.1. Mecânica Newtoniana</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/modelagem_matematica/pages/jupytered/c07/0702-Mecanica_Lagrangiana">7.2. Mecânica Lagrangiana</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/modelagem_matematica/pages/jupytered/c07/0703-Conservacao_contexto_Newtoniano">7.3. Leis de conservação em um contexto Newtoniano</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/modelagem_matematica/pages/jupytered/c07/0704-Conservacao_contexto_Lagrangiano">7.4. Leis de conservação em um contexto Lagrangiano</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/modelagem_matematica/pages/jupytered/c07/0705-Hamiltonianos">7.5. Hamiltonianos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/modelagem_matematica/pages/jupytered/c07/0706-Pendulo">7.6. Análise do período de um pêndulo planar simples</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/modelagem_matematica/pages/jupytered/c07/0707-Pendulo_angulos_grandes">7.7. Experimentos com pêndulos</a></li>
    </div>
    <div class="menu-level-1">
    <li>8. Modelos em Eletrônica</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/modelagem_matematica/pages/jupytered/c08/0801-Modelo_diodo">8.1. Modelagem da relação voltagem-corrente de um diodo</a></li>
    </div>
    <div class="menu-level-1">
    <li>9. Reações Químicas</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/modelagem_matematica/pages/jupytered/c09/0901-Lei_acao_de_massas">9.1. Lei de ação de massas</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/modelagem_matematica/pages/jupytered/c09/0902-Reacoes_enzimaticas">9.2. Modelagem de reações enzimática</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/modelagem_matematica/pages/jupytered/c09/0903-Isomerizacao">9.3. Lupulagem e a conversão de humulone em iso-humulone considerando saturação</a></li>
    </div>
<div>


  
    <a href="https://github.com/rmsrosa/modelagem_matematica/tree/modmat2022p1"><img src="/modelagem_matematica/assets/images/GitHub-Mark-32px.png" alt="GitHub repo" width="18" style="margin:5px 5px" align="left"></a>

  

</aside>


  <div class="books-content">

    
      <div class="navbar">
    <p id="nav">
<span id="nav-prev" style="float: left;">
<a class="menu-level-1" href="/modelagem_matematica/pages/jupytered/c05/0502-Minimos_quadrados_verossimilhanca">5.2. Mínimos quadrados, maximização da verossimilhança e quantificação de incertezas em regressões lineares <kbd>←</kbd></a>
</span>
<span id="nav-next" style="float: right;">
    <a class="menu-level-1" href="/modelagem_matematica/pages/jupytered/c06/0601-Qualidade_do_modelo"><kbd>→</kbd> 6.1. Qualidade do ajuste</a>
</span>
    </p>
</div>
</br></br>

    

    
      <div class="badges">
<p>
<a href="https://nbviewer.org/urls/rmsrosa.github.io/modelagem_matematica/generated/jupytered/c05/0503-Propagacao_incertezas.ipynb"><img align="left" src="https://img.shields.io/badge/view%20in-nbviewer-orange" alt="View in NBViewer" title="View Jupyter notebook in NBViewer"></a>
<a href="https://mybinder.org/v2/gh/rmsrosa/modelagem_matematica/julia-env-for-binder-2022p1?urlpath=git-pull%3Frepo%3Dhttps://github.com/rmsrosa/modelagem_matematica%26urlpath%3Dlab/tree%252Fmodelagem_matematica/generated/jupytered/c05/0503-Propagacao_incertezas.ipynb%26branch%3Dgh-pages"><img align="left" src="https://mybinder.org/badge.svg" alt="Open in binder" title="Open in binder"></a>
<a href="/modelagem_matematica/generated/jupytered/c05/0503-Propagacao_incertezas.ipynb"><img align="left" src="https://img.shields.io/badge/download-notebook-blue" alt="Download notebook" title="Download Jupyter notebook"></a>
<a href="/modelagem_matematica/src/jupyter/c05/0503-Propagacao_incertezas.ipynb"><img align="left" src="https://img.shields.io/badge/view-source-lightblue" alt="View source" title="View source"></a>
</p>
</div></br>

    
<h1 id="get_title"><a href="#get_title" class="header-anchor">5.3. Propagação de incertezas</a></h1>
<pre><code class="language-julia">using Plots
using Distributions
using Random
using LsqFit
using Statistics</code></pre>
<h2 id="introdução"><a href="#introdução" class="header-anchor">Introdução</a></h2>
<ul>
<li><p>Dado um modelo \(y=f(\boldsymbol\beta, \mathbf{x})\), onde \(\beta\) indica um vetor de parâmetros do modelo e \(x\) um vetor de variáveis independentes, buscamos estimar as incertezas em \(y\) em termos de incertezas em \(\boldsymbol\beta\) e em \(\mathbf{x}\).</p>
</li>
<li><p>De maneira análoga, podemos buscar entender quão sensível a resposta \(y\) é a  variações em \(\boldsymbol\beta\) e em \(\mathbf x\).</p>
</li>
<li><p>No último caderno, vimos isso no caso de um modelo linear \(y=\beta_0 + \beta_1 x\) e de incertezas na escolha dos parâmetros \(\beta_0\) e \(\beta_1\).</p>
</li>
<li><p>Vamos, agora, explorar mais um pouco essa questão.</p>
</li>
<li><p>Podemos, naturalmente, considerar um modelo vetorial, \(\mathbf{y} = \mathbf{f}(\boldsymbol\beta, \mathbf{x})\). Mas, em muitos casos, essa análise, pode ser reduzida ao caso escalar, coordenada a coordenada. Para simplificar, vamos considerar apenas o caso escalar.</p>
</li>
</ul>
<h2 id="incertezas"><a href="#incertezas" class="header-anchor">Incertezas</a></h2>
<ul>
<li><p>Nessa <em>quantificação de incertezas</em>, ou de <em>análise de sensibilidade</em>, tanto os parâmetros \(\boldsymbol\beta\) como as variáveis independentes \(\mathbf x\) são consideradas variáveis aleatórias.</p>
</li>
<li><p>Vamos denotar as incertezas nessas quantidades por \(\delta\boldsymbol\beta\) e \(\delta\mathbf x\).</p>
</li>
<li><p>Ou, em coordenadas específicas, \(\delta\beta_j\) e \(\delta x_i\).</p>
</li>
</ul>
<h2 id="propagação_de_incertezas_em_modelos_lineares"><a href="#propagação_de_incertezas_em_modelos_lineares" class="header-anchor">Propagação de incertezas em modelos lineares</a></h2>
<ul>
<li><p>Vamos começar com um modelo linear afim</p>
</li>
</ul>
\[ y = \beta_0 + \beta_1 x_1 + \ldots + \beta_m x_m = \boldsymbol\beta \mathbf{x},
\]
<p>onde \(\boldsymbol\beta = (\beta_0, \beta_1, \ldots, \beta_m)\) e \(\mathbf{x} = (1, x_1, \ldots, x_m)\).</p>
<ul>
<li><p>Este é um modelo em \(m\)-dimensões, com \(m+1\) parâmetros. Apenas uma ligeira extensão do caso visto anteriormente.</p>
</li>
<li><p>Nesse caso, a propagação em relação aos parâmetros é como antes:</p>
</li>
</ul>
\[ \delta y = \delta\beta_0 + \delta\beta_1 x_1 + \ldots + \delta\beta_m x_m = (\delta \boldsymbol\beta) \mathbf{x}.
\]
<ul>
<li><p>Escrevendo \(x_0 = 1\) para facilitar a notação, a variância de \(y\) é como antes:</p>
</li>
</ul>
\[ \operatorname{Var}(y) = E((\delta y)^2) = E\left(((\delta \boldsymbol\beta) \mathbf{x})^2\right) = E\left(\left(\sum_{j=0}^m (\delta\beta_j) x_j\right)^2\right) =  E\left(\sum_{i,j=0}^m (\delta\beta_i)(\delta\beta_j)x_ix_j\right) \\ = \sum_{i,j=0}^m E((\delta\beta_i)(\delta\beta_j))x_ix_j =  \mathbf{x}^T \operatorname{Cov}(\delta\boldsymbol\beta)\mathbf{x}.
\]
<h2 id="propagação_de_incertezas_em_modelos_não_lineares"><a href="#propagação_de_incertezas_em_modelos_não_lineares" class="header-anchor">Propagação de incertezas em modelos não lineares</a></h2>
<h3 id="propagação_local_de_incertezas_via_linearização"><a href="#propagação_local_de_incertezas_via_linearização" class="header-anchor">Propagação local de incertezas via linearização</a></h3>
<ul>
<li><p>Para variações pequenas, em modelos não-lineares, podemos linearizar o modelo.</p>
</li>
<li><p>No caso \(y = f(\boldsymbol\beta, \mathbf{x})\),</p>
</li>
</ul>
\[\delta y = f(\hat{\boldsymbol\beta} + \delta\boldsymbol\beta,\mathbf{x}) - f(\hat{\boldsymbol\beta}) \approx \nabla_{\boldsymbol\beta} f(\hat{\boldsymbol\beta}, \mathbf{x}) (\delta\boldsymbol\beta).
\]
<ul>
<li><p>Com a linearização,</p>
</li>
</ul>
\[ \operatorname{Var}(y) = \nabla_{\boldsymbol\beta} f(\hat{\boldsymbol\beta}, \mathbf{x})^T\operatorname{Cov}(\delta\boldsymbol\beta) \nabla_{\boldsymbol\beta} f(\hat{\boldsymbol\beta}, \mathbf{x})
\]
<h3 id="propagação_global"><a href="#propagação_global" class="header-anchor">Propagação global</a></h3>
<ul>
<li><p>Há uma série de métodos globais, como <a href="https://en.wikipedia.org/wiki/Morris_method">Morris <em>one-at-a-time</em> &#40;OTA&#41;</a>, <a href="https://en.wikipedia.org/wiki/Variance-based_sensitivity_analysis">Sobol/Variância &#40;ANOVA&#41;</a>, <a href="https://en.wikipedia.org/wiki/Fourier_amplitude_sensitivity_testing">Fourier Amplitude Sensitivity Testing &#40;FAST&#41;</a> e <a href="https://en.wikipedia.org/wiki/Quasi-Monte_Carlo_method">Quasi-Monte Carlo</a>.</p>
</li>
<li><p>Aqui, no entanto, vamos considerar apenas o <a href="https://en.wikipedia.org/wiki/Monte_Carlo_method">método de Monte Carlo</a> clássico.</p>
</li>
<li><p>Neste método, geramos aleatoriamente uma amostra de parâmetros, segundo uma determinada distribuição, aplicamos o modelo e calculamos as estatísticas do resultado &#40;e.g. média e intervalos de confiança&#41;.</p>
</li>
</ul>
<h2 id="exemplo_de_reação_enzimática"><a href="#exemplo_de_reação_enzimática" class="header-anchor">Exemplo de reação enzimática</a></h2>
<ul>
<li><p>Neste exemplo, vamos usar aproximação local por derivação para estimar o erro nos parâmetros.</p>
</li>
<li><p>E vamos usar propagação global via método de Monte-Carlo para estimar o erro no modelo a partir dos erros locais nos parâmetros.</p>
</li>
<li><p>O exemplo é o mesmo exemplo de reação enzimática feito no caderno sobre otimização não-linear.</p>
</li>
</ul>
<h3 id="definindo_os_parâmetros_da_reação_original"><a href="#definindo_os_parâmetros_da_reação_original" class="header-anchor">Definindo os parâmetros da reação original</a></h3>
<pre><code class="language-julia">function model&#40;t, β&#41;
    ν_m &#61; β&#91;1&#93;
    K_M &#61; β&#91;2&#93;
    v &#61; &#40;ν_m .* t&#41; ./ &#40;K_M .&#43; t&#41;
    return v
end

ν_m &#61; 0.3
K_M &#61; 0.5
β &#61; &#91;ν_m K_M&#93;
nothing</code></pre>
<h3 id="colhendo_amostra_e_visualizando_os_dados"><a href="#colhendo_amostra_e_visualizando_os_dados" class="header-anchor">Colhendo amostra e visualizando os dados</a></h3>
<pre><code class="language-julia">data_t &#61; &#91;0.03, 0.15, 0.3, 0.6, 1.3, 2.5, 3.5&#93;

data_v &#61; model&#40;data_t, β&#41; .&#43; 0.02*randn&#40;MersenneTwister&#40;503&#41;, length&#40;data_t&#41;&#41;
t &#61; 0:0.1:4
plot&#40;t, t -&gt; model&#40;t, β&#41;, label&#61;&quot;taxa de reação&quot;, legend&#61;:bottomright&#41;
plot&#33;&#40;data_t, data_v, seriestype&#61;:scatter, label&#61;&quot;amostra com ruído&quot;&#41;</code></pre>
<img src="/modelagem_matematica/assets/pages/jupytered/c05/0503-Propagacao_incertezas/code/images/0503-Propagacao_incertezas_3_1.png" alt="">
<h3 id="ajustando_os_parâmetros_via_lsqfit"><a href="#ajustando_os_parâmetros_via_lsqfit" class="header-anchor">Ajustando os parâmetros via <code>LsqFit</code></a></h3>
<pre><code class="language-julia">β₀ &#61; &#91;0.5, 0.5&#93;
fit &#61; curve_fit&#40;model, data_t, data_v, β₀&#41;</code></pre>
<pre><code class="language-julia">LsqFit.LsqFitResult&#123;Vector&#123;Float64&#125;, Vector&#123;Float64&#125;, Matrix&#123;Float64&#125;, Vect
or&#123;Float64&#125;&#125;&#40;&#91;0.33783348970169996, 0.7526693327901114&#93;, &#91;0.0022878584673871
345, -0.003539069472438726, 0.007927265930752145, 0.005723230500783993, -0.
004370304010106824, -0.03195144785139303, 0.027980441478012763&#93;, &#91;0.0383303
6346635541 -0.016545020878989205; 0.16617380756190187 -0.06219229486324708;
 … ; 0.7685994929725614 -0.07982940235274255; 0.8230124954670534 -0.0653803
9091892706&#93;, true, Float64&#91;&#93;&#41;</code></pre>
<h3 id="estatísticas_do_ajuste"><a href="#estatísticas_do_ajuste" class="header-anchor">Estatísticas do ajuste</a></h3>
<ul>
<li><p>Abaixo, obtemos</p>
<ul>
<li><p>os parâmetros ajustados;</p>
</li>
<li><p>o erro padrão;</p>
</li>
<li><p>a margem de 95&#37; de erro;</p>
</li>
<li><p>o intervalo de 95&#37; de confiança;</p>
</li>
<li><p>a matriz variância-covariância.</p>
</li>
</ul>
</li>
</ul>
<pre><code class="language-julia">β_fit &#61; fit.param</code></pre>
<pre><code class="language-julia">2-element Vector&#123;Float64&#125;:
 0.33783348970169996
 0.7526693327901114</code></pre>
<pre><code class="language-julia">σ &#61; stderror&#40;fit&#41;</code></pre>
<pre><code class="language-julia">2-element Vector&#123;Float64&#125;:
 0.029934302312525682
 0.195586287280632</code></pre>
<pre><code class="language-julia">margin_of_error &#61; margin_error&#40;fit, 0.05&#41;</code></pre>
<pre><code class="language-julia">2-element Vector&#123;Float64&#125;:
 0.07694857378702462
 0.5027705573831384</code></pre>
<pre><code class="language-julia">confidence_inter &#61; confidence_interval&#40;fit, 0.05&#41;</code></pre>
<pre><code class="language-julia">2-element Vector&#123;Tuple&#123;Float64, Float64&#125;&#125;:
 &#40;0.26088491591467533, 0.4147820634887246&#41;
 &#40;0.24989877540697303, 1.2554398901732498&#41;</code></pre>
<pre><code class="language-julia">covar &#61; estimate_covar&#40;fit&#41;</code></pre>
<pre><code class="language-julia">2×2 Matrix&#123;Float64&#125;:
 0.000896062  0.00517513
 0.00517513   0.038254</code></pre>
<h3 id="observações"><a href="#observações" class="header-anchor">Observações</a></h3>
<ul>
<li><p>O erro padrão informado via <code>LsqFit.stderror&#40;&#41;</code> é a raiz quadrada dos elementos da diagonal da matriz de variância-covariância.</p>
</li>
<li><p>A matriz de variância-covariância <code>LsqFit.estimate_covar&#40;&#41;</code> é obtida via aproximação local, a partir da matriz jacobiana e do erro quadrático médio ajustado pelo número de parâmetros.</p>
</li>
<li><p>Vamos verificar isso&#33;</p>
</li>
</ul>
<pre><code class="language-julia">sqrt.&#40;&#91;covar&#91;1,1&#93;,covar&#91;2,2&#93;&#93;&#41;</code></pre>
<pre><code class="language-julia">2-element Vector&#123;Float64&#125;:
 0.029934302312525682
 0.195586287280632</code></pre>
<pre><code class="language-julia">jac &#61; fit.jacobian</code></pre>
<pre><code class="language-julia">7×2 Matrix&#123;Float64&#125;:
 0.0383304  -0.016545
 0.166174   -0.0621923
 0.28499    -0.0914619
 0.443567   -0.110782
 0.633322   -0.104234
 0.768599   -0.0798294
 0.823012   -0.0653804</code></pre>
<pre><code class="language-julia">mse&#40;fit&#41; * inv&#40;jac&#39; * jac&#41;</code></pre>
<pre><code class="language-julia">2×2 Matrix&#123;Float64&#125;:
 0.000896062  0.00517513
 0.00517513   0.038254</code></pre>
<h3 id="observações__2"><a href="#observações__2" class="header-anchor">Observações</a></h3>
<ul>
<li><p>Vale ressaltar que o erro quadrático médio <code>mse&#40;&#41;</code> calculado pelo <code>LsqFit.jl</code> leva em consideração o grau de liberdade do modelo, dividindo por \(N - p\), onde \(N\) é o número de dados e \(p\) é o número de parâmetros</p>
</li>
<li><p>Esse ajuste é adequado para uma estimativa apropriada do erro padrão.</p>
</li>
</ul>
<pre><code class="language-julia">mse&#40;fit&#41;</code></pre>
<pre><code class="language-julia">0.0003872511807690104</code></pre>
<pre><code class="language-julia">length&#40;data_v&#41;, length&#40;β_fit&#41;</code></pre>
<pre><code class="language-julia">&#40;7, 2&#41;</code></pre>
<pre><code class="language-julia">sum&#40;abs2, data_v - model&#40;data_t, β_fit&#41;&#41; / &#40;length&#40;data_v&#41; - length&#40;β_fit&#41;&#41;</code></pre>
<pre><code class="language-julia">0.0003872511807690104</code></pre>
<h3 id="amostragem_dos_parâmetros"><a href="#amostragem_dos_parâmetros" class="header-anchor">Amostragem dos parâmetros</a></h3>
<ul>
<li><p>Pelo método de Monte Carlo, fazemos uma amostragem nos parâmetros e observamos as estatísticas do resultado do modelo com esses parâmetros.</p>
</li>
<li><p>Como os parâmetros estão correlacionados, usamos uma normal bidimensional, com a matriz de variância-covariância fornecida pelo método de otimização.</p>
</li>
<li><p>Observe a seguir a diferença entre fazer a amostragem levando em consideração ou não a correlação entre os parâmetros.</p>
</li>
</ul>
<pre><code class="language-julia">num_amostras &#61; 1000
plot&#40;title&#61;&quot;Duas amostras, uma sem correlação e outra com correlação&quot;, titlefont&#61;10&#41;
scatter&#33;&#40;&#40;r -&gt; &#40;r&#91;1,:&#93;, r&#91;2,:&#93;&#41;&#41;&#40;rand&#40;MersenneTwister&#40;13000&#41;, MvNormal&#40;β_fit,covar&#41;, num_amostras&#41;&#41;, label&#61;&quot;com correlação&quot;&#41;
scatter&#33;&#40;&#40;rand&#40;Normal&#40;β_fit&#91;1&#93;,σ&#91;1&#93;&#41;,num_amostras&#41;,
        rand&#40;Normal&#40;β_fit&#91;2&#93;,σ&#91;2&#93;&#41;,num_amostras&#41;&#41;, label&#61;&quot;sem correlação&quot;,
        legend&#61;:topleft&#41;</code></pre>
<img src="/modelagem_matematica/assets/pages/jupytered/c05/0503-Propagacao_incertezas/code/images/0503-Propagacao_incertezas_16_1.png" alt="">
<h3 id="resultado_da_propagação_de_erro_via_método_de_monte_carlo"><a href="#resultado_da_propagação_de_erro_via_método_de_monte_carlo" class="header-anchor">Resultado da propagação de erro via Método de Monte Carlo</a></h3>
<ul>
<li><p>Usando a amostragem considerando a correlação entre parâmetros, fazemos diversas simulações.</p>
</li>
</ul>
<pre><code class="language-julia">t &#61; 0:0.1:4
num_amostras &#61; 100
simulations &#61; fill&#40;0.0, length&#40;t&#41;, num_amostras&#41;
plot&#40;t, t -&gt; model&#40;t, β&#41;, label&#61;&quot;taxa original&quot;, legend&#61;:bottomright,
    title&#61;&quot;Modelo sintético, modelo ajustado, simulações e média das simulações&quot;, titlefont&#61;10&#41;
plot&#33;&#40;data_t, data_v, seriestype&#61;:scatter, label&#61;&quot;amostra com ruído&quot;&#41;
plot&#33;&#40;t, t -&gt; model&#40;t, β_fit&#41;, label&#61;&quot;modelo ajustado&quot;, legend&#61;:bottomright&#41;

for &#40;n,β̃&#41; in enumerate&#40;eachcol&#40;rand&#40;MersenneTwister&#40;13000&#41;, MvNormal&#40;β_fit,covar&#41;, num_amostras&#41;&#41;&#41;
    modelagem &#61; model.&#40;t,Ref&#40;β̃&#41;&#41;
    simulations&#91;:,n&#93; &#61; model.&#40;t,Ref&#40;β̃&#41;&#41;
    plot&#33;&#40;t, simulations&#91;:,n&#93;, label&#61;false, alpha&#61;0.1 , legend&#61;:bottomright, color&#61;3&#41;
end
plot&#33;&#40;t, mean&#40;simulations, dims&#61;2&#41;, color&#61;4, label&#61;&quot;média simulações&quot;&#41;</code></pre>
<img src="/modelagem_matematica/assets/pages/jupytered/c05/0503-Propagacao_incertezas/code/images/0503-Propagacao_incertezas_17_1.png" alt="">
<h3 id="intervalo_de_confiança"><a href="#intervalo_de_confiança" class="header-anchor">Intervalo de confiança</a></h3>
<ul>
<li><p>Nesse caso, o resultado da simulação em tempos diferentes não é mais independente do tempo.</p>
</li>
<li><p>O próprio modelo leva a uma correlação entre os resultados das simulações em tempos diferentes.</p>
</li>
<li><p>Por esse motivo, não podemos apelar para o Teorema do Limite Central para definir o intervalo de confiança.</p>
</li>
<li><p>Os intervalos de confiança devem ser obtidos diretamente dos percentis das simulações.</p>
</li>
<li><p>Dessa forma, é natural que os intervalos de confiança não sejam simétricos em relação à média.</p>
</li>
<li><p>De qualquer forma, vamos fazer, abaixo, dos dois jeitos, para efeito de comparação.</p>
</li>
</ul>
<pre><code class="language-julia">plot&#40;t, t -&gt; model&#40;t, β&#41;, label&#61;&quot;taxa original&quot;, legend&#61;:bottomright,
    title&#61;&quot;Incluindo intervalo de confiança de 95&#37; assumindo independência temporal&quot;, titlefont&#61;10&#41;
plot&#33;&#40;data_t, data_v, seriestype&#61;:scatter, label&#61;&quot;amostra com ruído&quot;&#41;
plot&#33;&#40;t, t -&gt; model&#40;t, β_fit&#41;, label&#61;&quot;modelo ajustado&quot;, legend&#61;:bottomright&#41;

for n in 1:num_amostras
    plot&#33;&#40;t, simulations&#91;:,n&#93;, label&#61;false, alpha&#61;0.1 , legend&#61;:bottomright, color&#61;3&#41;
end
plot&#33;&#40;t, mean&#40;simulations, dims&#61;2&#41;, yerror&#61;2*sqrt.&#40;var&#40;simulations, dims&#61;2&#41;&#41;, color&#61;4,
    label&#61;&quot;média simulações&quot;&#41;</code></pre>
<img src="/modelagem_matematica/assets/pages/jupytered/c05/0503-Propagacao_incertezas/code/images/0503-Propagacao_incertezas_18_1.png" alt="">
<ul>
<li><p>Calculando os percentis a partir dos dados das simulações.</p>
</li>
</ul>
<pre><code class="language-julia">quantiles95 &#61;
    reduce&#40;vcat, &#91;quantile&#40;simulations&#91;i,:&#93;, &#91;0.025 0.975&#93;&#41; for i in 1:length&#40;t&#41;&#93;&#41;

errorbar95 &#61; quantiles95 .- mean&#40;simulations, dims&#61;2&#41;</code></pre>
<pre><code class="language-julia">41×2 Matrix&#123;Float64&#125;:
  0.0         0.0
 -0.00911759  0.016708
 -0.0138763   0.0244809
 -0.0162127   0.0268753
 -0.0171647   0.0263309
 -0.0174861   0.0252796
 -0.0173037   0.0235826
 -0.0172024   0.0221576
 -0.0169754   0.0199883
 -0.0166392   0.0180607
  ⋮           
 -0.0292301   0.0297784
 -0.0298128   0.0305654
 -0.0303718   0.0313236
 -0.0309084   0.0320544
 -0.0314239   0.0327592
 -0.0319195   0.0334393
 -0.0323963   0.0340959
 -0.0328554   0.0347302
 -0.0332977   0.0353432</code></pre>
<pre><code class="language-julia">plot&#40;t, t -&gt; model&#40;t, β&#41;, label&#61;&quot;taxa original&quot;, legend&#61;:bottomright,
    title&#61;&quot;Incluindo intervalo de confiança de 95&#37; considerando correlações temporais&quot;, titlefont&#61;10&#41;
plot&#33;&#40;data_t, data_v, seriestype&#61;:scatter, label&#61;&quot;amostra com ruído&quot;&#41;
plot&#33;&#40;t, t -&gt; model&#40;t, β_fit&#41;, label&#61;&quot;modelo ajustado&quot;, legend&#61;:bottomright&#41;
for n in 1:num_amostras
    plot&#33;&#40;t, simulations&#91;:,n&#93;, label&#61;false, alpha&#61;0.1 , legend&#61;:bottomright, color&#61;3&#41;
end
plot&#33;&#40;t, mean&#40;simulations, dims&#61;2&#41;, yerror&#61;errorbar95, color&#61;4,
    label&#61;&quot;média simulações&quot;&#41;</code></pre>
<img src="/modelagem_matematica/assets/pages/jupytered/c05/0503-Propagacao_incertezas/code/images/0503-Propagacao_incertezas_20_1.png" alt="">
<ul>
<li><p>Comparando os dois intervalos de confiança.</p>
</li>
<li><p>Nesse exemplo, a diferença não foi considerável. Mas em outras situações, pode ser.</p>
</li>
</ul>
<pre><code class="language-julia">plot&#40;t, t -&gt; model&#40;t, β&#41;, label&#61;&quot;taxa original&quot;, legend&#61;:bottomright,
    title&#61;&quot;Original, média e diferentes cálculos do intervalo de confiança de 95&#37;&quot;, titlefont&#61;10&#41;
plot&#33;&#40;t, t -&gt; model&#40;t, β_fit&#41;, color&#61;2, label&#61;&quot;modelo ajustado&quot;&#41;
plot&#33;&#40;t, mean&#40;simulations, dims&#61;2&#41;, color&#61;3, label&#61;&quot;média simulações&quot;&#41;
plot&#33;&#40;t, quantiles95, color&#61;4, label&#61;&#91;&quot;percentil 95&#37; considerando correlação temporal&quot; nothing&#93;&#41;
plot&#33;&#40;t, mean&#40;simulations, dims&#61;2&#41; .&#43; 2*sqrt.&#40;var&#40;simulations, dims&#61;2&#41;&#41;, color&#61;6,
    label&#61;&quot;percentil 95&#37; considerando independência temporal&quot;&#41;
plot&#33;&#40;t, mean&#40;simulations, dims&#61;2&#41; .- 2*sqrt.&#40;var&#40;simulations, dims&#61;2&#41;&#41;, color&#61;6,
    label&#61;nothing&#41;</code></pre>
<img src="/modelagem_matematica/assets/pages/jupytered/c05/0503-Propagacao_incertezas/code/images/0503-Propagacao_incertezas_21_1.png" alt="">
<h2 id="exercícios"><a href="#exercícios" class="header-anchor">Exercícios</a></h2>
<ol>
<li><p>Refaça os exemplos do caderno sobre <strong>Modelos redutíveis ao caso linear nos parâmetros e aplicações</strong> como problemas de otimização não-linear e faça as estatísticas de cada um deles, como feito acima.</p>
</li>
<li><p>Compare os intervalo de confiança obtidos no exercício acima com os intervalos de confiança obtidos no caderno anterior, sobre <strong>Mínimos quadrados, maximização da verossimilhança e quantificação de incertezas em regressões lineares</strong>, feito transformando os problemas em regressões lineares.</p>
</li>
</ol>

    <div class="navbar">
    <p id="nav">
<span id="nav-prev" style="float: left;">
<a class="menu-level-1" href="/modelagem_matematica/pages/jupytered/c05/0502-Minimos_quadrados_verossimilhanca">5.2. Mínimos quadrados, maximização da verossimilhança e quantificação de incertezas em regressões lineares <kbd>←</kbd></a>
</span>
<span id="nav-next" style="float: right;">
    <a class="menu-level-1" href="/modelagem_matematica/pages/jupytered/c06/0601-Qualidade_do_modelo"><kbd>→</kbd> 6.1. Qualidade do ajuste</a>
</span>
    </p>
</div>
</br></br>



<div class="page-foot">
    
        <div class="license">
            <a href=https://creativecommons.org/licenses/by-nc-nd/4.0/>(CC BY-NC-ND 4.0) Attribution-NonCommercial-NoDerivatives 4.0 International </a>
            
        </div>
    

    Last modified: June 21, 2022. Built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a>.
</div><!-- CONTENT ENDS HERE -->

      </div> <!-- .books-content -->
    </div> <!-- .books-container -->

    
        <script src="/modelagem_matematica/libs/katex/katex.min.js"></script>
        <script src="/modelagem_matematica/libs/katex/auto-render.min.js"></script>
        <script>renderMathInElement(document.body)</script>
    

    
        <script src="/modelagem_matematica/libs/highlight/highlight.pack.js"></script>
        <script>hljs.initHighlightingOnLoad();hljs.configure({tabReplace: '    '});</script>
    

  </body>
</html>
